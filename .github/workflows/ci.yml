name: Data Engineering CI

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  ci:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: airflow
          POSTGRES_PASSWORD: airflow
          POSTGRES_DB: airflow
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U airflow"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      # ---------------------------
      # Checkout
      # ---------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # ---------------------------
      # Python setup
      # ---------------------------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
      
          # Define the constraints URL for Airflow 2.8.1 and Python 3.10
          export CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-2.8.1/constraints-3.10.txt"
      
          # 1. Uninstall any pre-existing airflow to avoid conflicts
          pip uninstall -y apache-airflow || true
      
          # 2. Install Airflow with constraints (this handles Flask-Session automatically)
          pip install "apache-airflow[postgres]==2.8.1" --constraint "${CONSTRAINT_URL}"
      
          # 3. Install your specific project requirements
          pip install -r requirements.txt
      
          # 4. Install dev tools and other integrations
          pip install \
            pytest \
            ruff \
            black \
            dbt-core \
            dbt-snowflake
      
          # 5. Install local package if applicable
          pip install -e .
      # Python quality
      # ---------------------------
      - name: Lint with ruff
        run: ruff check .

      - name: Check formatting with black
        run: black --check .

      # ---------------------------
      # Unit tests
      # ---------------------------
      - name: Run unit tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python -m pytest

      # ---------------------------
      # Airflow DAG validation
      # ---------------------------
      - name: Validate Airflow DAGs
        env:
          AIRFLOW__CORE__EXECUTOR: SequentialExecutor
          AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@localhost:5432/airflow
          AIRFLOW__CORE__LOAD_EXAMPLES: "false"
        run: |
          airflow db migrate
          python - <<EOF
          from airflow.models import DagBag
          dagbag = DagBag()
          if dagbag.import_errors:
              raise Exception(dagbag.import_errors)
          print(f"Loaded {len(dagbag.dags)} DAGs successfully")
          EOF

      # ---------------------------
      # DBT validation (Snowflake-ready)
      # ---------------------------
      - name: DBT compile
        run: |
          cd dbt/weather_dbt
          dbt compile --profiles-dir .
